# -*- coding: utf-8 -*-
"""Untitled59.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x0X0CaFFklSntbe208Etf7332TmI4EW0
"""

!pip install -q langchain gradio openai pypdf tiktoken


import os
from langchain import OpenAI
from langchain.document_loaders import PyPDFLoader
from langchain import PromptTemplate
# Loaders
from langchain.schema import Document

# Splitters
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Model
from langchain.chat_models import ChatOpenAI

# Embedding Support
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings

# Summarizer we'll use for Map Reduce
from langchain.chains.summarize import load_summarize_chain

# Data Science
import numpy as np
from sklearn.cluster import KMeans

from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

# Taking out the warnings
import warnings
from warnings import simplefilter

import gradio as gr

with open('openai_api_key.txt', 'r') as file:
  openai_api_key = file.readline()


def summarize_pdf(pdf_path):
  llm = OpenAI(temperature=0, openai_api_key=openai_api_key)
  # Load the book
  loader = PyPDFLoader(pdf_path)
  pages = loader.load()

  # Combine the pages, and replace the tabs with spaces
  text = ""

  for page in pages:
      text += page.page_content

  text = text.replace('\t', ' ')

  num_tokens = llm.get_num_tokens(text)

  text_splitter = RecursiveCharacterTextSplitter(separators=["\n\n", "\n", "\t"], chunk_size=10000, chunk_overlap=3000)
  docs = text_splitter.create_documents([text])

  num_documents = len(docs)

  embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
  vectors = embeddings.embed_documents([x.page_content for x in docs])

  num_clusters = num_documents // 3
  # Perform K-means clustering
  kmeans = KMeans(n_clusters=num_clusters, random_state=42).fit(vectors)

  # Filter out FutureWarnings
  simplefilter(action='ignore', category=FutureWarning)

  # Perform t-SNE and reduce to 2 dimensions
  tsne = TSNE(n_components=2, perplexity=3, random_state=42)
  reduced_data_tsne = tsne.fit_transform(np.array(vectors))

  # Find the closest embeddings to the centroids

  # Create an empty list that will hold your closest points
  closest_indices = []

  # Loop through the number of clusters you have
  for i in range(num_clusters):

      # Get the list of distances from that particular cluster center
      distances = np.linalg.norm(vectors - kmeans.cluster_centers_[i], axis=1)

      # Find the list position of the closest one (using argmin to find the smallest distance)
      closest_index = np.argmin(distances)

      # Append that position to your closest indices list
      closest_indices.append(closest_index)

  selected_indices = sorted(closest_indices)
  llm3 = ChatOpenAI(temperature=0,
                 openai_api_key=openai_api_key,
                 max_tokens=1000,
                 model='gpt-3.5-turbo'
                )
  map_prompt = """
  You will be given a single passage of a book. This section will be enclosed in triple backticks (```)
  Your goal is to give a summary of this section so that a reader will have a full understanding of what happened.
  Your response should be at least three paragraphs and fully encompass what was said in the passage.

  ```{text}```
  FULL SUMMARY:
  """
  map_prompt_template = PromptTemplate(template=map_prompt, input_variables=["text"])
  map_chain = load_summarize_chain(llm=llm3,
                             chain_type="stuff",
                             prompt=map_prompt_template)
  selected_docs = [docs[doc] for doc in selected_indices]

  # Make an empty list to hold your summaries
  summary_list = []

  # Loop through a range of the lenght of your selected docs
  for i, doc in enumerate(selected_docs):

      # Go get a summary of the chunk
      chunk_summary = map_chain.run([doc])

      # Append that summary to your list
      summary_list.append(chunk_summary)

  return summary_list

input_pdf_path = gr.components.Textbox(label="Provide the PDF file path")
output_summary = gr.components.Textbox(label="Summary")

interface = gr.Interface(
    fn=summarize_pdf,
    inputs=input_pdf_path,
    outputs=output_summary,
    title="PDF Summarizer",
    description="Provide PDF file path to get the summary.",
).launch(share=True)

